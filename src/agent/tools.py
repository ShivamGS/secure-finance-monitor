"""
Agent tools for the finance monitoring agent.

These tools wrap MCP server calls and add agent-level logic.
They are registered with the OpenAI Agents SDK as function_tools.
"""

import json
import re
import base64
import logging
from datetime import datetime

from agents import function_tool

logger = logging.getLogger(__name__)

# Prompt injection detection patterns
_INJECTION_PATTERNS: list[tuple[str, re.Pattern]] = [
    ("ignore_instructions", re.compile(r"ignore\s+(all\s+)?(previous|prior|above|your)\s+(instructions|rules|guidelines|directives)", re.IGNORECASE)),
    ("ignore_all_rules", re.compile(r"ignore\s+all\s+(safety\s+)?rules", re.IGNORECASE)),
    ("system_prompt", re.compile(r"(system\s+prompt|system\s+message|initial\s+prompt)", re.IGNORECASE)),
    ("output_reveal", re.compile(r"(output|reveal|show|display|list|print|include)\s+(?:\w+\s+){0,3}(all|every)\s+(?:\w+\s+){0,2}(credit|card|ssn|account|personal|private|pii|secret)\s+numbers?", re.IGNORECASE)),
    ("data_exfiltration", re.compile(r"(all|every)\s+(credit\s+card|account|ssn|personal|private)\s+numbers?\s*\(?(full|unmasked|complete)", re.IGNORECASE)),
    ("forget_instructions", re.compile(r"forget\s+(your|all|previous)\s+(instructions|rules|guidelines|training)", re.IGNORECASE)),
    ("role_override", re.compile(r"you\s+are\s+now\s+(?!a\s+secure)", re.IGNORECASE)),
    ("act_as", re.compile(r"act\s+as\s+(if\s+you\s+are|a|an)\s+(?!secure\s+finance)", re.IGNORECASE)),
    ("disregard", re.compile(r"(disregard|override|bypass|circumvent|disable)\s+(your|all|the|any)\s+\w*\s*(rules|instructions|safety|security|guidelines|restrictions|protections?)", re.IGNORECASE)),
    ("do_not_redact", re.compile(r"do\s+not\s+(redact|censor|hide|mask|remove|filter)", re.IGNORECASE)),
    ("base64_block", re.compile(r"[A-Za-z0-9+/]{40,}={0,2}", re.IGNORECASE)),
]

# Module-level pipeline statistics for chat mode display
_last_pipeline_stats = {
    "fetched": 0,
    "blocked": 0,
    "redacted": 0,
    "injections": 0,
    "stored": 0
}


def get_last_pipeline_stats() -> dict:
    """Get the most recent pipeline statistics from tool execution."""
    return dict(_last_pipeline_stats)


@function_tool
def scan_financial_emails(days: int = 30, max_results: int = 100) -> str:
    """
    Scan Gmail for recent financial emails. Returns extracted transaction data.

    Args:
        days: Number of days to look back (default 30)
        max_results: Maximum number of emails to return (default 100, max 100)
    """
    from ..mcp_server.server import fetch_financial_emails
    from .extractor import extract_transaction
    from ..config.blocklist import get_blocklist

    # Limit max_results to 100 to match scan command default
    max_results = min(max_results, 100)

    logger.info(f"ðŸ“§ Scanning Gmail: last {days} days, max {max_results} emails")
    result = fetch_financial_emails(days=days, max_results=max_results)
    emails = result.get('emails', [])
    total_redactions = result.get('total_redactions', 0)  # Preserve from MCP server
    logger.info(f"ðŸ“¬ Found {len(emails)} emails")

    # Apply blocklist pre-filtering (Task 7: Cequence demo)
    blocklist = get_blocklist()
    emails_after_blocklist = []
    blocked_count = 0

    for email in emails:
        sender = email.get("sender", "")
        subject = email.get("subject", "")
        is_blocked, reason = blocklist.is_blocked(sender, subject)

        if is_blocked:
            blocked_count += 1
            logger.debug(f"Blocked email by {reason}: {subject[:50]}")
        else:
            emails_after_blocklist.append(email)

    logger.info(f"ðŸš« Blocklist filtered out {blocked_count}/{len(emails)} emails")
    emails = emails_after_blocklist

    # Extract transaction data from each email using smart extractor
    transactions = []
    skipped = 0

    for email in emails:
        try:
            # Map redacted_body to body for extractor compatibility
            email_for_extraction = {
                "id": email.get("id", ""),
                "sender": email.get("sender", ""),
                "subject": email.get("subject", ""),
                "date": email.get("date", ""),
                "body": email.get("redacted_body", ""),  # Map redacted_body -> body
            }

            transaction = extract_transaction(email_for_extraction)
            if transaction:
                transactions.append(transaction)
            else:
                skipped += 1
                logger.debug(f"Skipped email {email.get('id')} - not a financial transaction")
        except Exception as e:
            logger.warning(f"Failed to extract from email {email.get('id')}: {e}")
            skipped += 1

    logger.info(f"âœ… Extracted {len(transactions)} transactions, skipped {skipped} non-financial emails")

    # Update module-level stats for chat mode display
    _last_pipeline_stats["fetched"] = len(emails)
    _last_pipeline_stats["blocked"] = blocked_count
    _last_pipeline_stats["redacted"] = total_redactions
    _last_pipeline_stats["injections"] = 0  # Updated by check_prompt_injection if called
    _last_pipeline_stats["stored"] = len(transactions)

    return json.dumps({
        'total_emails': len(emails),
        'blocked_count': blocked_count,
        'transactions_found': len(transactions),
        'total_redactions': total_redactions,  # Pass through from MCP server
        'skipped': skipped,
        'transactions': transactions,
        'summary': f'Extracted {len(transactions)} transactions from {len(emails)} emails ({blocked_count} blocked, {skipped} skipped)'
    }, default=str)


@function_tool
def categorize_transaction(merchant: str, amount: float, email_snippet: str) -> str:
    """
    Categorize a financial transaction by merchant, amount, and context.

    Args:
        merchant: The merchant or sender name
        amount: The dollar amount of the transaction
        email_snippet: A redacted snippet of the email for context
    """
    from .llm_backend import get_llm_backend
    from .prompts import CATEGORIZATION_PROMPT

    backend = get_llm_backend()

    prompt_input = (
        f"{CATEGORIZATION_PROMPT}\n"
        f"Merchant: {merchant}\n"
        f"Amount: ${amount:.2f}\n"
        f"Context: {email_snippet[:500]}\n"
    )

    response = backend.complete(prompt_input)

    # Try to parse as JSON; fall back to raw response
    try:
        parsed = json.loads(response)
    except (json.JSONDecodeError, TypeError):
        parsed = {
            "merchant": merchant,
            "amount": amount,
            "category": _infer_category_local(merchant, email_snippet),
            "is_subscription": _is_likely_subscription(merchant, email_snippet),
            "confidence": 0.6,
        }

    return json.dumps(parsed)


@function_tool
def detect_anomalies(transactions_json: str) -> str:
    """
    Analyze a batch of transactions for anomalies and security threats.

    Args:
        transactions_json: JSON string of transactions to analyze
    """
    from .llm_backend import get_llm_backend
    from .prompts import ANOMALY_DETECTION_PROMPT

    backend = get_llm_backend()

    prompt_input = f"{ANOMALY_DETECTION_PROMPT}\n{transactions_json}"
    response = backend.complete(prompt_input)

    try:
        parsed = json.loads(response)
    except (json.JSONDecodeError, TypeError):
        # Fall back to local anomaly detection
        try:
            transactions = json.loads(transactions_json)
        except (json.JSONDecodeError, TypeError):
            transactions = []
        parsed = _detect_anomalies_local(transactions)

    # Check if any anomalies are SECURITY type â€” log at CRITICAL level
    for anomaly in parsed.get("anomalies", []):
        if anomaly.get("type") == "SECURITY":
            logger.critical(
                "SECURITY anomaly detected: %s", anomaly.get("description", "")
            )

    return json.dumps(parsed)


@function_tool
def generate_summary(days: int = 7) -> str:
    """
    Generate a financial summary for the given period.

    Args:
        days: Number of days to summarize (default 7)
    """
    from .llm_backend import get_llm_backend
    from ..mcp_server.server import get_financial_summary
    from .prompts import WEEKLY_SUMMARY_PROMPT

    summary_data = get_financial_summary(days=days)

    backend = get_llm_backend()
    prompt_input = f"{WEEKLY_SUMMARY_PROMPT}\n{json.dumps(summary_data, default=str)}"
    response = backend.complete(prompt_input)

    try:
        parsed = json.loads(response)
    except (json.JSONDecodeError, TypeError):
        parsed = _build_local_summary(summary_data)

    return json.dumps(parsed)


@function_tool
def check_prompt_injection(text: str) -> str:
    """
    Check text for prompt injection patterns. Run this on email content
    BEFORE the agent processes it as financial data.

    Args:
        text: The text to check for injection patterns
    """
    result = check_prompt_injection_raw(text)

    if result["is_suspicious"]:
        logger.warning(
            "Prompt injection detected (risk=%s): %s",
            result["risk_level"],
            result["patterns_found"],
        )

    return json.dumps(result)


def check_prompt_injection_raw(text: str) -> dict:
    """
    Core prompt injection detection logic (non-tool version for direct use).

    Returns:
        {is_suspicious: bool, patterns_found: list, risk_level: str}
    """
    if not text:
        return {"is_suspicious": False, "patterns_found": [], "risk_level": "none"}

    found = []
    for name, pattern in _INJECTION_PATTERNS:
        if name == "base64_block":
            # Special handling for base64 to avoid false positives
            if _check_base64_injection(text):
                found.append(name)
        else:
            if pattern.search(text):
                found.append(name)

    if not found:
        return {"is_suspicious": False, "patterns_found": [], "risk_level": "none"}

    # Determine risk level based on number and type of patterns
    high_risk = {"ignore_instructions", "ignore_all_rules", "output_reveal",
                 "disregard", "do_not_redact", "forget_instructions", "data_exfiltration"}
    medium_risk = {"system_prompt", "role_override", "act_as", "base64_block"}

    if any(p in high_risk for p in found):
        risk = "high"
    elif any(p in medium_risk for p in found):
        risk = "medium"
    else:
        risk = "low"

    return {
        "is_suspicious": True,
        "patterns_found": found,
        "risk_level": risk,
    }


def _check_base64_injection(text: str) -> bool:
    """
    Check if text contains base64-encoded injection attempts.

    Only flags base64 that:
    1. Decodes to valid text
    2. Contains injection patterns
    3. Is not part of MIME/email structure

    Returns True if suspicious base64 injection found.
    """
    # Skip if this looks like MIME content or email boundaries
    mime_indicators = [
        "Content-Type:", "Content-Transfer-Encoding:", "boundary=",
        "multipart/", "text/html", "text/plain", "image/",
        "MIME-Version:", "charset=", "name=", "filename="
    ]

    if any(indicator in text for indicator in mime_indicators):
        return False

    # Find base64-like patterns (min 60 chars to avoid short false positives)
    base64_pattern = re.compile(r'[A-Za-z0-9+/]{60,}={0,2}')
    matches = base64_pattern.findall(text)

    if not matches:
        return False

    # Try to decode each match and check for injection patterns
    for match in matches:
        try:
            decoded_bytes = base64.b64decode(match, validate=True)
            decoded_text = decoded_bytes.decode('utf-8', errors='ignore')

            # Check if decoded text contains injection keywords
            injection_keywords = [
                "ignore", "disregard", "override", "bypass",
                "system prompt", "reveal", "output all", "disable",
                "redact", "unfiltered", "unrestricted", "admin",
                "credit card", "ssn", "account number", "pii"
            ]

            decoded_lower = decoded_text.lower()
            if any(keyword in decoded_lower for keyword in injection_keywords):
                # Additional check: must have both a command word and a target
                has_command = any(word in decoded_lower for word in ["ignore", "disregard", "override", "bypass", "disable", "reveal", "output"])
                has_target = any(word in decoded_lower for word in ["instructions", "rules", "safety", "redact", "credit", "ssn", "account", "pii"])

                if has_command and has_target:
                    logger.warning(f"Suspicious base64 decoded to: {decoded_text[:100]}")
                    return True

        except (base64.binascii.Error, UnicodeDecodeError, ValueError):
            # Not valid base64 or not valid UTF-8, skip
            continue

    return False


# =====================================================================
# Local fallback logic (when LLM is unavailable)
# =====================================================================

_SUBSCRIPTION_MERCHANTS = {
    # Streaming
    "netflix", "spotify", "hulu", "disney", "disney+", "apple tv", "apple music",
    "amazon prime", "youtube", "youtube premium", "hbo", "hbo max", "paramount",
    "paramount+", "peacock", "espn+", "showtime", "starz", "crunchyroll",
    "tidal", "pandora", "deezer", "apple one",
    # Software & Cloud
    "adobe", "microsoft", "office 365", "microsoft 365", "dropbox", "icloud",
    "google one", "google workspace", "github", "jetbrains", "notion",
    "evernote", "lastpass", "1password", "dashlane", "grammarly", "canva",
    "figma", "slack", "zoom", "webex", "teams",
    # News & Media
    "new york times", "washington post", "wall street journal", "medium",
    "substack", "patreon", "audible", "kindle unlimited",
    # Fitness & Health
    "peloton", "strava", "myfitnesspass", "headspace", "calm", "noom",
    # Gaming
    "playstation", "xbox", "nintendo", "steam", "epic games", "ea play",
    # Other
    "patreon", "onlyfans", "memberful", "squarespace", "wix", "godaddy",
}

_CATEGORY_KEYWORDS = {
    "Groceries": ["whole foods", "trader joe", "grocery", "safeway", "kroger", "costco", "target", "walmart grocery"],
    "Dining": ["restaurant", "starbucks", "mcdonald", "chipotle", "nobu", "dinner", "cafe", "grubhub", "doordash", "ubereats"],
    "Transport": ["uber", "lyft", "gas", "shell", "chevron", "parking", "transit", "payrange", "gofun"],
    "Entertainment": ["netflix", "spotify", "hulu", "disney", "movie", "theater", "concert", "event"],
    "Subscriptions": ["subscription", "renewed", "membership", "monthly", "annual"],
    "Shopping": ["amazon", "best buy", "walmart", "ebay", "order", "shipped", "staples", "ulta", "groupon"],
    "Bills/Utilities": ["electric", "water", "internet", "phone bill", "insurance", "statement", "payment due"],
    "Healthcare": ["pharmacy", "doctor", "hospital", "medical", "dental", "health", "alevea"],
    "Travel": ["airline", "hotel", "airbnb", "booking", "flight", "travel", "southwest", "expedia"],
    "Income": ["received", "deposit", "payroll", "salary", "cashback", "cash back", "reward", "refund", "reimbursement"],
    "Transfer": ["venmo", "zelle", "cashapp", "transfer", "sent you", "paid you", "ziprecruiter"],
}

# Priority patterns checked first (more specific)
_PRIORITY_PATTERNS = [
    # Credit card companies - cashback/rewards are Income
    (r'\b(?:discover|chase|capital one|citi|citibank|amex|american express|bank of america)\b.*\b(?:cashback|cash back|reward|bonus|rebate)\b', "Income"),
    (r'\b(?:cashback|cash back|reward|bonus|rebate)\b.*\b(?:discover|chase|capital one|citi|citibank|amex|american express|bank of america)\b', "Income"),

    # Credit card companies - payments/statements are Bills
    (r'\b(?:discover|chase|capital one|citi|citibank|amex|american express|bank of america)\b.*\b(?:payment received|payment confirmation|thank you for your payment|statement|balance due|minimum payment|amount due)\b', "Bills/Utilities"),
    (r'\b(?:statement|balance due|minimum payment|amount due|payment received)\b.*\b(?:discover|chase|capital one|citi|citibank|amex|american express|bank of america)\b', "Bills/Utilities"),

    # Credit card companies - default to Bills if no other context
    (r'\b(?:discover card|chase sapphire|chase freedom|capital one|citi card|citibank|amex|american express|bank of america)\b', "Bills/Utilities"),

    # Income patterns (cashback, rewards, refunds) - general
    (r'\b(?:cashback|cash back|reward|refund|reimbursement)\b', "Income"),
    (r'\b(?:received|deposit)\b.*(?:from|payment)', "Income"),

    # Bill payments (payments TO banks/utilities)
    (r'\bpayment\s+(?:to|for)\b', "Bills/Utilities"),
    (r'\b(?:credit card|card)\s+payment\b', "Bills/Utilities"),

    # Airlines (before general travel)
    (r'\b(?:southwest|united|delta|american airlines|jetblue)\b', "Travel"),

    # Food delivery
    (r'\b(?:doordash|grubhub|ubereats|postmates)\b', "Dining"),
]


def _infer_category_local(merchant: str, context: str = "") -> str:
    """Infer transaction category from merchant name and context.

    Uses priority patterns for specific cases (cashback, bill payments),
    then falls back to keyword matching.
    """
    text = f"{merchant} {context}".lower()

    # Check priority patterns first (more specific)
    for pattern, category in _PRIORITY_PATTERNS:
        if re.search(pattern, text, re.IGNORECASE):
            return category

    # Fall back to keyword matching
    for category, keywords in _CATEGORY_KEYWORDS.items():
        if any(kw in text for kw in keywords):
            return category

    return "Other"


def _is_likely_subscription(merchant: str, context: str = "") -> bool:
    """
    Check if a merchant is a known subscription service.

    Checks:
    1. Known subscription merchant names
    2. Subscription keywords in context (renewed, subscription, monthly, etc.)
    """
    merchant_lower = merchant.lower()

    # Check known merchants
    if merchant_lower in _SUBSCRIPTION_MERCHANTS:
        return True

    # Check if any known merchant is a substring
    if any(known in merchant_lower for known in _SUBSCRIPTION_MERCHANTS):
        return True

    # Check for subscription keywords in context
    subscription_keywords = [
        "subscription", "renewed", "membership", "monthly", "annual",
        "recurring", "auto-renew", "plan has been", "premium plan"
    ]

    context_lower = context.lower()
    return any(keyword in context_lower for keyword in subscription_keywords)


def _detect_anomalies_local(transactions: list) -> dict:
    """Basic local anomaly detection without LLM."""
    from datetime import datetime, timedelta

    anomalies = []

    if not isinstance(transactions, list):
        return {"anomalies": [], "summary": "No transactions to analyze"}

    # Check for duplicates (same merchant + same amount + within 24 hours)
    for i, txn1 in enumerate(transactions):
        if not isinstance(txn1, dict):
            continue

        merchant1 = txn1.get("merchant", "")
        amount1 = txn1.get("amount", 0.0)
        date1_str = txn1.get("date", "")

        if not merchant1 or not amount1:
            continue

        try:
            date1 = datetime.fromisoformat(date1_str) if date1_str else None
        except (ValueError, TypeError):
            date1 = None

        for txn2 in transactions[i+1:]:
            if not isinstance(txn2, dict):
                continue

            merchant2 = txn2.get("merchant", "")
            amount2 = txn2.get("amount", 0.0)
            date2_str = txn2.get("date", "")

            # Check if same merchant and amount (within $0.01)
            if merchant1.lower() == merchant2.lower() and abs(amount1 - amount2) <= 0.01:
                # Check date proximity (within 24 hours)
                try:
                    date2 = datetime.fromisoformat(date2_str) if date2_str else None
                except (ValueError, TypeError):
                    date2 = None

                # Only flag if within 24 hours or dates unknown
                time_diff = None
                if date1 and date2:
                    time_diff = abs((date1 - date2).total_seconds() / 3600)  # hours

                if time_diff is None or time_diff <= 24:
                    anomalies.append({
                        "type": "DUPLICATE",
                        "severity": "medium",
                        "description": f"Possible duplicate: {merchant1} ${amount1:.2f}" + (f" ({time_diff:.1f}h apart)" if time_diff else ""),
                        "transactions_involved": [
                            txn1.get("email_id", ""),
                            txn2.get("email_id", ""),
                        ],
                        "recommended_action": "Review for duplicate charges",
                    })
                    break  # Only flag once per transaction

    return {
        "anomalies": anomalies,
        "summary": f"Found {len(anomalies)} potential anomalies in {len(transactions)} transactions",
    }


def _build_local_summary(summary_data: dict) -> dict:
    """Build a basic summary without LLM."""
    transactions = summary_data.get("transactions", [])
    total = 0.0
    by_category: dict[str, float] = {}
    merchants: dict[str, dict] = {}

    for txn in transactions:
        for amt_str in txn.get("amounts", []):
            try:
                amt = float(amt_str.replace("$", "").replace(",", ""))
            except (ValueError, AttributeError):
                continue
            total += amt
            cat = txn.get("category_hint", "Other")
            by_category[cat] = by_category.get(cat, 0) + amt
            m = txn.get("merchant", "Unknown")
            if m not in merchants:
                merchants[m] = {"total": 0, "count": 0}
            merchants[m]["total"] += amt
            merchants[m]["count"] += 1

    top = sorted(merchants.items(), key=lambda x: x[1]["total"], reverse=True)[:5]

    return {
        "period": f"last {summary_data.get('query_days', 7)} days",
        "total_spent": round(total, 2),
        "by_category": {k: round(v, 2) for k, v in by_category.items()},
        "top_merchants": [
            {"name": m, "total": round(d["total"], 2), "count": d["count"]}
            for m, d in top
        ],
        "subscriptions_detected": [],
        "anomalies_detected": 0,
        "insights": [],
        "security_flags": 0,
    }
